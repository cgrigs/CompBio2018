{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your data are huge. I'm not going to load them to the Hub for everyone. So instead, I'll have you upload it yourself, to your personal instance of the Hub.\n",
    "\n",
    "Navigate into the data directory and look for the \"Upload\" button as shown below.\n",
    "\n",
    "![hubload](img/UploadButton.png)\n",
    "\n",
    "Click the button and navigate to your data. On my connection, it took a couple minutes to upload.\n",
    "\n",
    "Unpacking sff files is pretty easy, now. sff files are read by biopython, a python library for processing sequence data and performing various biology-related functions, mainly file input and output. We will specifically be working with the sequence input and output module. The documents specific to sff parsing are [here](http://biopython.org/DIST/docs/api/Bio.SeqIO.SffIO-module.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. (5 pts) Three important properties of the parsed sff are id, annotation and seq. In the below loop, modify the print statement to access the id, annotation and seq attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in SeqIO.parse(\"../data/SRR170500.sff\", \"sff\"):\n",
    "    print(record.annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. (5 pts) In this loop, have we saved any data as variables? Why might doing our initial explorations in this way be advisable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. (5 pts) When printing the sequence, you may notice that some nucleotides are in upper case and some in lower. What does this mean? You may want to consult the documents on this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. (10 pts) Next, have a look at the convert() function about 1/3 of the way down the page. Export the data as a FASTA file. Save it as SRR170550.fasta. What are the relative data sizes of the sff file and the fasta? Why is this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. (10 pts) Take the code above and write it as a function. The function should take as input the input and output file paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. (5 pts) Use SeqIO to load the fasta file to a list. [These documents](https://biopython.org/wiki/SeqIO) may be helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. (5 pts) What are the items in this list? Below, use a for loop to get the record id from each record. Hint: will we index each item in the list like a list, or like a dataframe column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = list(SeqIO.parse(\"../data/SRR170500.fasta\", \"fasta\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. (5 pts) Next, we're going to look at BLASTing some of these sequences to see what they are. If we BLAST the whole dictionary, it will be slow, and we will probably be kicked off of NCBI. What would be a reasonable way to divide up either the file or the dictionary to BLAST? Describe your approach below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. (10 pts) Now, execute your strategy for getting chunks of five sequences at a time. Save your five sequences to a list called blast_list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0 \n",
    "blast_list = []\n",
    "for value in records:\n",
    "    while i < 5:\n",
    "        blast_list.append(value)\n",
    "        i = i + 1\n",
    "print(blast_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. (15 pts) Now, we will do the BLAST search. I have included an import statement for the module you will use. I would like you to loop over blast_list. I would like you to save your results to a list called results_list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.Blast import NCBIWWW\n",
    "results_list = []\n",
    "for result in blast_list[0:1]:\n",
    "    results_list.append(NCBIWWW.qblast(\"blastn\", \"nt\", result.seq, format_type=\"text\"))\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. (5 pts) What format are these results in?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. (5 pts) Write the results to a file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. (10 pts) I'm not going to ask for you to start parsing these data, but \n",
    "for one entry, but using the following commands (edit results file to whatever your output was), are you able to tell what the fields are in the file? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "\n",
    "tree = ET.parse(results_file)\n",
    "root = tree.getroot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. (5 pts) What will be the most relevant fields to extract for your question?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonus (2 pts). What is one thing that is going well in this class? And one that isn't? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
