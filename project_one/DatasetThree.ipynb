{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Project One\n",
    "\n",
    "Below are the questions for the first data practical assignment. This project is for the Piller students. \n",
    "The point value of each question is denoted next to it. A blank cell is below each for your answer; feel free to create more blank cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 10 pts. I do not want to make your data available to the whole class, so follow these instructions to upload your data. First, in the graphical interface, navigate to the data directory. Click the 'Upload' button.\n",
    "\n",
    "![upload](img/UploadButton.png)\n",
    "\n",
    "Choose your data file to upload. \n",
    "\n",
    "Import the pandas library and load the data. You will use `read_excel`, rather than `read_csv`, for obvious reasons. You may want to look at the `header` argument - are your column names in row 0 or row 1? Save the data in a variable called project_dat. Print the data to the screen to ensure it loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel(\"../data/messy_data_set.xlsx\", skiprows=0, header=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. (5pts) Check the datatypes of each column. Use a comment to note if there are any that surprise you. (Hint: look at the data type (float, int), and the precision of the numbers in the columns). In the comments, also note what steps you would have to take before you could change the datatype in the columns to comething more sensical (hint: think about missing data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Specimen', 'Standard length', 'Predorsal length', 'preanal length',\n",
       "       'prepelvic length', 'prepectoral length', 'dorsal-fin base length',\n",
       "       'dorsal fin origin to pectoral origin',\n",
       "       'dorsal fin origin to pelvic origin', 'dorsal terminus to anal origin',\n",
       "       'dorsal terminus to pelvic origin', 'dorsal origin to adipose origin',\n",
       "       'adipose origin to hypural plate', 'pectoral origin to pelvic origin',\n",
       "       'anal-fin base length', 'anal origin to adipse origin',\n",
       "       'length of caudal peduncle',\n",
       "       'Adipose origin to base of last anal fin ray', 'Maxillary length',\n",
       "       'snout length', 'vertical orbit diameter', 'head length',\n",
       "       'anterior margin of orbit to maxilla'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. (5 pts) Look at your data spreadsheet in a spreadsheet viewer. What are the missing data values. In your opinion, are these intelligent missing values for the dataset? Why or why not? If not, how would you like to change them?  The below cell is a markdown cell, meaning it will hold text input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. (5 pts) Subset the data: let's make a new dataframe that contains only the rows that are specimens. That is, get rid of the rows that are summary stats or other measures. Call it subset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. (5 pts) Next, let's replace those cm and no data values. In plain language, what do we need to do to replace the cm and no data measurements?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. (10 pts) Perform the operations you described in (8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. (5 pts) For the surprising datatypes in columns in question 2, you should now be able to change the columns that should be numeric to numeric types (int or float). Do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. (5 points) Are there any columns in your dataset that contain two pieces of data? If so, identify them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. (5pts) Split the 'specimen' column into two columns - one that is the specimen number, and one that is whether the specimen is a holotype, a paratype or neither (just use missing data for this). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. (5 pts) Group the data based on if a specimen is a holo, para or neither type. How many of each are there?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. (5 pts) Save the dataframe with the split columns into the data directory. Save it as a csv file called \"column_separated.csv\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. (10 pts) Write a function that does the column splitting, the grouping, and the count. It should take one argument, the subset_df, as input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. (15 pts) Next, move the function to a script. The output from your script should be a CSV file, with the column splitting operation performed. How would you like to return the results of the grouping and counting operation from your code? (this last bit is a genuine matter of opinion). Make sure you have your script anatomy correct! For this part, do not worry about passing in the input and output datafiles, simply hard code them in. Save the script in the scripts directory as \"question_14.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. (5 pts) Now, we're going to think about passing in the input and output data files. Make a copy of your script and title it \"question_16.py\". Would you rather use argparse or sys to pass in the name of the input file and output file? This is an opinion question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16. (5 pts) Set up the input and output argument passing you described above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonus: (2 pts). What is one thing you feel like you get really well? What is one thing you don't?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
