{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# October 16\n",
    "\n",
    "**Conflict**\n",
    "\n",
    "![](https://media.giphy.com/media/3oz8xABuMZ7AsrcMc8/giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warm Up \n",
    "It is possible to have multiple owners of a GitHub repository. For our warm-up today, we're going to do an exercise. Get into pairs.\n",
    "\n",
    "1. Partner 1 & 2: Navigate to the github page for your Lastname_project\n",
    "2. Partner 1: Go to \"Settings.\" Click \"Collaborators.\" Enter your partner's GitHub name.\n",
    "3. Partner 2: You might get an email notification saying that you've been added.\n",
    "4. Partner 2: Clone your partner's repo. Copy the repository location by clicking on the big, green \"Clone or download\" button. Open a new terminal, and type:\n",
    "\n",
    "```git clone ``` followed by the address you copied.\n",
    "5. Partner 2: Now, pick a file. Change something in it. Doesn't matter what, but it has to be something were there is already text on that line.\n",
    "6. Partner 2: Add, commit and push your code.\n",
    "7. Partner 1: Pull in your partner's changes. Do you see conflict?\n",
    "8. Partner 1: Open the conflict file in a text editor, and let me know once you have your conflict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resolving Conflict\n",
    "\n",
    "This is a little bit social, and a little bit technical. You made a change to something that was. And in a co-owned repo, no one needs to approve your changes. You just get to make them! \n",
    "\n",
    "So how can we resolve these issues? \n",
    "\n",
    "1. **Read** First, I normally look at the changes. What did this person do? Can I see why? \n",
    "2. **Ask** If I don't understand, I ask for help.\n",
    "3. **Decide** Then I do the merge, and add and commit the code. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBIF\n",
    "\n",
    "We're at a bit of a crossroads in the course: a lot of the end part of the class is about making websites, and other forms of communicating results. But I think it would help if we did a little more fun programming stuff first.\n",
    "\n",
    "We're going to get some occurrence data off of GBIF, the website for the Global Biodiversity Information Facility website. We're going to see if we can get some information on where these salamanders live.\n",
    "\n",
    "First, we will get the names of the salamanders. I've put an empty cell below, and below it an answer. See if you can read in the `plethodon.phy` file with Dendropy, and get the names of our salamanders.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## Answer below\n",
    "import dendropy\n",
    "\n",
    "sal_dat = dendropy.DnaCharacterMatrix.get_from_path(\"../data/plethodon.phy\", schema=\"phylip\")\n",
    "sal_names = sal_dat.taxon_namespace.labels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll use a library called `pygbif`, which interfaces with GBIF to get locality information for our salamanders. We will search each salamander name against the GBIF database to get locations where that salamander is found. We are only going to do this for a couple salamanders, to keep the exercise tractable for all of us to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pygbif import occurrences\n",
    "\n",
    "list_of_dictionaries = []\n",
    "\n",
    "for name in sal_names[1:5]:\n",
    "    sal_dict = occurrences.search(scientificName = name)\n",
    "    list_of_dictionaries.append(sal_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 53 records for the salamaders in our sample - all our salamanders were found.  The data download as a dictionary, and for ease of processing, we will change these into dataframes. If you view one of the dictionaries, there's a lot of padding - we really only want the \"results\" entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dict_one = list_of_dictionaries[0]['results']\n",
    "sal_df = pd.DataFrame.from_dict(dict_one)\n",
    "\n",
    "for item in list_of_dictionaries:\n",
    "    temp_df = pd.DataFrame.from_dict(item['results'])\n",
    "    sal_df = sal_df.append(temp_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look at the dataframe, you'll see that there's a lot of information here, and lots of different ways that we could subset the data. For example, perhaps we only want records where a person physically saw the salamander: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sal_slim = sal_df[sal_df.basisOfRecord == \"HUMAN_OBSERVATION\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is still quite a bit of data! However, many databases don't process null records, or give an error if the record is null. So, let's remove the NaN values, and also save our work to a file. That way if the internet dies, or something, we still have our searches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "locs = sal_slim.dropna(subset=['verbatimLocality'])\n",
    "locs.to_csv(\"../data/locs.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you notice about these localities? \n",
    "\n",
    "We'll need to locate them to coordinates before we can plot them. To do this, we will use an open-source package call geopy, which takes in a string of a location and searches that string against a global map to get Lat and Long coordinates. We will use the values in the `locs` `verbatimLocality` column to do this. \n",
    "\n",
    "## Exercise Two: Talk the below code out with a partner. Decide what it does, and then run it to confirm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "import numpy as np\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"class\")\n",
    "locs['coords'] = 0\n",
    "locations = []\n",
    "for row in locs.verbatimLocality.iteritems():\n",
    "    latlong = geolocator.geocode(row[1])\n",
    "    if latlong is None:\n",
    "        locations.append(0)\n",
    "    else: \n",
    "        locations.append(latlong[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a list. Use the below cell to confirm that the list is the same length as the locations dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an important step called `testing`. What would it mean if the list was not the same length? Would we want to keep using it? \n",
    "\n",
    "Next we will append the list as a new column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se = pd.Series(locations)\n",
    "locs['coords'] = se.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now do three last activities: \n",
    "- Write this raw data into our data folder as a CSV file.\n",
    "- Decide how we want to treat missing values (0-values), and apply this treatment.\n",
    "- Write out the treated data as separate from the raw data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
